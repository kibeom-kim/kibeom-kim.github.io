---
title: 카프카, 데이터 플랫폼의 최강자 9장
date: 2025-04-01
update: 2025-04-01
tags: 
	- kafka
---

# 9장 카프카 SQL 을 이용한 스트리밍 처리
카프카가 스트리밍 처리를 위한 중간 데이터를 모으는 곳으로 많이 사용되고 있다. 
단기간 처리는 스트리밍 플랫폼으로 하고 장기 데이는 별도의 장기 저장소와 별도의 배치 시스템을 사용하는 방법이 일반적이었다.

## 9.1 KSQL 의 등장 배경
카프카가 다른 메시지 큐에 비해 부족한 기능이 바로 특정 큐로 데이터가 들어왔을 때 정해진 룰 또는 이 큐의 데이터를 처리해서 다른 큐로전달하는 큐 라우팅 기능 -> 삼자 samza 라는 소프트웨어

로raw 데이터를 처리해서 기간과 용량에 따라 별도의 저장소를 가져가는 것을 **람다 아키텍처**라고 한다.
- 장점
	- 파이프라인을 통해 큰 어려움없이 적절한 기술들을 연결해서 단기 데이터와 장기 데이터를 동시에 관리
	- 병목이 생길 경우 특정 컴포넌트만 증가시키면 된다
	- 데이터 조회 영역에서 큰 어려움 없이 단기/장기 데이터를 한 번에 조회할 수 있다
- 단점
	- 적절한 기술들을 연결한다는 것이 많은 기술을 사용해야한다는 의미
	- 단기 데이터와 장기 데이터를 별도로 관리해야 하기 때문에 관리비용이 부담(장비, 인력)


## 9.2 KSQL과 카파 아키텍처
- 데이터의 크기나 기간에 관계 없이 하나의 계산 프로그램을 사용하는 방식
- 람다 아키텍처와의 가장 큰 차이점은 장기 데이터를 미리 계산해서 빨리 조회할 수 있도록 따로 저장하는 것이 아니라 필요할 때 계산해서 결과를 전달하는 것
- 데이터 계산에 필요한 코드가 단기 데이터를 사용할 때는 카프카를, 장기 데이터가 필요할 때는 하둡과 같은 저장소를 사용하도록 개발해야 함
- 데이터를 가져오는  영역까지도 단순하게, 저장기간에 관계없이 통합되게 만들면 어떨까?가  KSQL의 시작

## 9.3 KSQL 아키텍처
- KSQL 서버와 셸 클라이어트로 나뉨
- KSQL 서버
	- 사용자 쿼리를 받는 REST API 서버, 쿼리를 실행하는 KSQL 엔진 클래스로 구성
	- 엔진은 쿼리를 실행계획으로 변환하고 지정된 카프카 클러스터의 토픽으로부터 데이터를 읽거나 토픽을 생성해 데이터를 생성하는 역할
- 클라이언트
	- 사용자가 SQL쿼리문을 작성할 수 있게 함

### KSQL 서버
- 논리/물리 실행계획을 세울 때 필요한 테이블 메타 정보는 KSQL 서버의 메모리에 저장
- 필요한 경우 ksql_commands 라는 카프카 토픽에 저장
- 해당 토픽에는 KSQL 서버 실행 후 실행한 테이블 관련 명령어가 있어 서버가 추가되었을 때 메타 데이터를 클러스터 간에 복제하는 것이 아니라 해당 토픽을 읽어서 자신의 메모리에 생성

### KSQL 클라이언트
- KSQL은 스트림을 처리하는 엔진이므로 테이블 외에 연속된 정형화된 데이터를 의미하는 스트림이라는 데이터 모델도 제공
- 스트림
	- 데이터가 계속 기록 될 수 있음
	- 한번 기록된 이벤트는 변경될 수 없음
	- 순서가 중요한 것은 스트림으로 생성
	- ex - 철수가 10원을 썼다. 그리고 철수가 10원을 벌었다.
- 테이블
	- 이벤트에 따른 현재 상태를 나타낸다
	- 기록된 이벤트가 변경, 삭제가 가능
	- ex - 철수가 10원을 써서 현재는 20원이다. 그리고 철수가 10원을 벌어서 현재는 30원이다.

### 스트림 생성
- create stream 스트림 이름 (컬럼이름 컬럼타입) with (프로퍼티_이름 = 프로퍼티 값 [, ...]);
- 지원 데이터 타입
	- boolean
	- integer (4byte)
	- bigint (8byte)
	- double
	- varchar(or string)
	- 배열형 (json만 지원)
	- 해시형 (json만 지원)
- 입력해야 하는 프로퍼티 종류
	- KAFKA_TOPIC (필수)
		- 테이블에서 사용할 토픽의 이름. 반드시 미리 생성
	- VALUE_FORMAT (필수)
		- 직렬화, 역직렬화시 사용할 포맷. json, csv만 지원
	- KEY
		- 토픽의 메시지 키와 컬럼을 연결
	- TIMESTAMP
		- 카프카 토픽의 timestamp와 컬럼을 연결

### 쿼리 결과로 스트림 생성
- select 결과를 카프카 토픽에 지속적으로 입력하도록  as select 사용
- partition by를 적용할 경우 해당 컬럼 이름을 토픽의 키로 사용
```plain
create stream stream_name
[with 프로퍼티_이름 = expression [, ...]]
as select 셀렉트 표현식
[partition by column_name]
```
- 프로퍼티
	- KAFKA_TOPIC
	- VALUE_FORMAT
	- TIMESTAMP
	- PARTITIONS
		- 토픽 생성 시 사용할 파티션 개수. 미설정 시 인풋 스트림이나 테이블의 값을 그대로 사용
	- REPLICATIONS
		- 토픽 생성 시 사용할 리플리케이션 팩터. 미설정 시 인풋 스트림이나 테이블의 값을 그대로 사용

### 테이블 생성
- 대부분 스트림 생성과 비슷하며  create 시 stream 대신 table 을 사용
- partition  by를 적용하면 해당 컬럼 이름을 토픽의 키로 사용하여 이후 쿼리 속도를 증가시킴
	- 느려진다는 것인가 빨라진다는 것인가

## 9.4 도커를 이용한 KSQL 클러스터 설치
- docker compose 를 이용하였으며 docker-compose.yaml에 필요한 3가지 서비스는 아래와 같다
	- zookeeper
	- kafka
	- schema-registry
