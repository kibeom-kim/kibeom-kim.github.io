---
title: 카프카, 데이터 플랫폼의 최강자 5장
date: 2025-03-27
update: 2025-03-27
tags: 
	- kafka
---

## 컨슈머란?
- 컨슈머 : 프로듀서가 메시지를 발행해서 브로커에 저장되고 난 후, 토픽의 메시지를 가져와서 소비하는 역할을 하는 애플리케이션, 서버등을 지칭
## 주요 기능
- 특정 파티션을 관리하고 있는 파티션 리더에게 요청해서 메시지를 가져오는 것
	- 가져올 메시지의 위치 지정 가능
	- 필요하다면 이미 가져온 데이터도 다시 가져올 수 있음 —> 잘못 컨슈밍하는 버전 배포 시점에 맞춰서 롤백후 다시 읽을 수 있다.

## 5.1 컨슈머 주요 옵션
- bootstrap.server
	- 카프카 클러스터에 연결하기 위해서 호스트와 포트정보로 구성된 리스트
- fetch.min.bytes
	- 한번에 가져올 수 있는 최소 데이터 사이즈. 지정한 사이즈보다 작은 경우 누적될때까지 기다림
- group.id
	- 컨슈머 그룹 식별자
- enable.auto.commit
	- 백그라운도로 주기적으로 오프셋을 커밋
- auto.offset.reset
	- 카프카에서 초기 오프셋이 없거나 현재 오프셋이 더 이상 존재하지 않는 경우 다음 옵션으로 리셋
	    - earliest: 가장 초기의 오프셋값
	    - latest: 가장 마지막의 오프셋값
	    - none: 이전 오프셋값을 찾지 못하면 에러
- fetch.max.bytes
	- 한번에 가져올 수 잇는 최대 데이터 사이즈
- request.timeout.ms
	- 요청에 대해 응답을 기다리는 시간
- session.timeout.ms
	- 컨슈머와 브로커 사이의 세션 타임아웃 시간.
    - 컨슈머는 컨슈머 그룹 코디네이터에게 지속적으로 하트비트를 보내는데, 이때 이 값 이상의 시간동안 하트비트를 보내지 않는다면 그룹 코디네이터는 해당 컨슈머에 장애가 발생했다고 판단하여 해당 컨슈머가 담당하는 파티션을 다른 컨슈머가 담당하는 리밸런스 시도
    - 기본값보다 낮게 설정하면, 실패를 빨리 감지하겠지만, 대신 컨슈머의 가비지 콜렉션(stop the world)라던가 poll 루프를 완료하는 시간이 길어지면 원치 않은 리밸런스가 발생할 수 있음
- heartbeat.interval.ms
	- 그룹 코디네이터에게 얼마나 자주 poll() 메소드로 하트비트를 보낼 것인지 조정.
	- session.timeout.ms보다 낮아야 하며 일반적으로 1/3로 설정(기본 3초)
	    - poll을 통해서 하트비트가 가는건 아니지만, poll()이 멈추면 하트비트도 멈추며 별도 스레드를 통해서 제어됨
	    - 비동기 컨슈밍이 추천되는 이유 중 하나.
		    - poll()에서 처리 로직을 동기로 실행하면 처리 시간에 따라서 하트 비트가 늘어지게 됨
			- 리밸런스가 의도치 않게 유도되는 케이스가 있을 수 있으니 비동기로 처리하는 것이 추천
- max.poll.records
	- 단일 호출 poll()에 대해서 최대 레코드 수를 조정
- max.poll.interval.ms
	- 컨슈머가 하트비트만 보내고 실제로 컨슈밍 하지 않는 경우가 있기 때문에 이 시간만큼 poll하지 않으면 리밸런스를 유도
- auto.commit.interval.ms
	- 주기적으로 메시지를 커밋하는 시간
- fetch.max.wait.ms
	- fetch.min.bytes에 의해서 설정된 데이터보다 적은 경우 이 시간만큼만 poll을 대기
	- 이 시간을 넘기면 데이터가 작아도 가져옴

## 컨슈머 동작 순서
### poll()
1. 컨슈머 -> 브로커로 poll()로 데이터 소비 호출
2. 브로커는 fetch.min.bytes보다 큰 데이터가 쌓였으면 그대로 데이터를 반환
	1. 이때 데이터의 최대 크기는 fetch.max.bytes를 넘지 않는다.
3. 컨슈머는 최대 max.poll.records만큼 데이터를 읽는다.
4. 만약에 fetch.max.byte만큼 데이터가 왔는데 max.poll.records가 작다면? 
	1. 남은 데이터는 컨슈머 내부 버퍼에 저장
	2. 다음 poll때는 브로커에게 데이터를 요청하지 않고 버퍼에 쌓인 레코드를 처리

## 5.4 파티션과 메시지 순서
- 여러 개의 파티션이 있는 경우 해당 파티션으로의 프로듀싱은 기본적으로 라운드로빈
- 따라서 하나의 프로듀서가 순서를 지켜서 프로듀싱해도 각 파티션으로 분산되어 저장되고 컨슈머는 분산된 파티션으로부터 읽기 때문에 순서를 지키기가 어려워짐

### 순서 보장
- 토픽의 파티션을 한 개로 구성
- 대신 분산해서 처리할 수 없고, 하나의 컨슈머에서만 처리할 수 있어 처리량이 낮음

## 5.5 컨슈머 그룹
- 하나의 토픽에 여러 컨슈머 그룹이 접속해서 메시지를 가져올 수 있음
- 하나의 데이터를 여러 용도로 사용할 수 있음
- 토픽의 데이터를 여러 용도로 사용해야 하는 경우 여러 용도의 숫자만큼 컨슈머 그룹을 만들어서 각 그룹이 다른 용도로 메시지를 처리할 수 있게 만듬
- 따라서 오프셋은 각 컨슈머 그룹마다 하나씩 존재
### 리밸런스
- 파티션의 소유권이 다른 컨슈머로 이동하는 것
- 예시)
	- **하나의 토픽, 3개의 파티션, 1개의 컨슈머 (컨슈머 1대는 3개의 파티션을 구독 중)**
	- 이때 프로듀싱이 많아지면 처리량이 떨어지게 되니, 최대 3개까지 컨슈머를 늘릴 수 있음
		- 즉 하나의 파티션이 하나의 컨슈머랑 매핑되는 것
	- 이때 컨슈머의 숫자를 늘려도 처리량이 늘어나지는 않음
		- 파티션 하나는 하나의 컨슈머에 의해서 컨슈밍되기 때문
	- 만약에 컨슈머의 숫자를 파티션의 숫자와 맞게 해줘도 처리량이 부족하다면, 파티션의 숫자, 컨슈머의 숫자를 4대로 늘리는것을 고려해야 함
- 리밸런스 동안 일시적으로 컨슈머 그룹 전체가 메시지를 가져올 수 없음
## 5.6 커밋과 오프셋
- 컨슈머는 각각의 파티션에 자신이 가져간 메시지의 위치 정보를 기록
- 현재 위치를 업데이트하는것을 커밋이라고 함
- 뉴 컨슈머에서는 카프카 내부에 별도로 사용하는 토픽(__consumer_offset)에 저장

### 5.6.1 자동 커밋
- enable.auto.commit = true로 세팅
- 5초 마다 poll() 호출시 가장 마지막 위치로 오프셋을 커밋
- 이때 주기는 auto.commit.interval.ms를 통해서 조절이 가능
- poll() 요청시마다 본인이 커밋을 해야하는 시간이 됬는지를 체크하고 커밋
- 리밸런스의 순간에는 중복 처리가 될 수 있음

### 5.6.2 수동 커밋
- 메시지 처리가 완료되기 전까지는 메시지를 가져온것으로 간주해서는 안되는 케이스
	- 예를 들어서 메시지를 가져와서 DB에 저장하는 로직
- 수동 커밋도 중복 발생 가능
	- 데이터베이스에 저장하는 도중 실패하면 마지막 커밋된 오프셋부터 메시지를 다시 가져오기 때문에 일부 메시지가 중복으로 저장될 수 있음
	- 카프카는 적어도 한번을 보장 (중복은 있지만 손실은 없다)