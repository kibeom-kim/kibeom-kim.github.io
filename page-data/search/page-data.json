{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"ACID란 무엇인가 ACID는 데이터베이스 신뢰성을 위한 네 가지 핵심 속성, 즉 Atomicity(원자성), Consistency(일관성), Isolation(격리성), Durability(지속성)을 말합니다. MySQL의 스토리지 엔진 중 하나인 InnoDB 엔진에서 어떻게 ACID를 지원하는지 알아보겠습니다. InnoDB 구조 개요 InnoDB는 M…","fields":{"slug":"/mysql-innodb-acid/"},"frontmatter":{"date":"September 08, 2025","title":"InnoDB와 ACID","tags":["MySQL","InnoDB"]},"rawMarkdownBody":"\n## ACID란 무엇인가\n\nACID는 데이터베이스 신뢰성을 위한 네 가지 핵심 속성, 즉 Atomicity(원자성), Consistency(일관성), Isolation(격리성), Durability(지속성)을 말합니다. MySQL의 스토리지 엔진 중 하나인 InnoDB 엔진에서 어떻게 ACID를 지원하는지 알아보겠습니다.\n\n## InnoDB 구조 개요\n\nInnoDB는 Memory, MyISAM과 더불어 MySQL의 대표적인 트랜잭션 스토리지 엔진입니다.\nACID를 위해 내부적으로 트랜잭션(undo/redo 로그), 버퍼 풀, MVCC 등 다양한 메커니즘이 작동합니다.\n\n### Atomicity(원자성)\n\n원자성이란 하나의 트랜잭션이 수행하는 작업 전체가 전부 성공하거나, 도중에 실패하면 전체가 원상복구(rollback)됨을 의미합니다.\n\nInnoDB는 언두(undo) 로그를 활용합니다:\n\n데이터 변경 시, 변경 전 기존 값을 언두 로그에 저장.\n트랜잭션이 실패하거나 ROLLBACK이 호출되면, 언두 로그를 따라 모든 변경사항이 철회됩니다.\n커밋 전에는 어떤 변경도 확정적으로 반영되지 않습니다.\n\n### Consistency(일관성)\n\n일관성은 트랜잭션의 실행 전후에 데이터의 논리적 무결성이 깨지지 않음을 보장합니다.\n\n무결성은 PK/UK/외래키 제약조건, CHECK 제약, 트리거 등으로 강제됩니다.\n\n트랜잭션이 실패하거나 롤백되면 일관성을 유지한 직전 상태로 복귀함을 보장합니다.\n\n### Isolation(격리성)\n\n    - 여러 트랜잭션이 동시에 작업할 때, 서로 간섭하지 않아야 데이터를 왜곡 없이 처리할 수 있습니다.\n    - InnoDB는 **MVCC(다중 버전 동시성 제어)**와 잠금을 병행 사용:\n        - 일반 SELECT는 언두 로그에 저장된 \"과거 버전\"으로부터, 트랜잭션 시작 시점의 일관된 스냅샷을 제공.\n    - DML/SELECT FOR UPDATE 등은 실제 데이터에 잠금을 걸어 동시성 문제를 방지.\n    - 격리 수준 선택:\n        - READ COMMITTED, REPEATABLE READ(기본값), SERIALIZABLE, READ UNCOMMITTED.\n        - 격리 수준이 높아질수록 동시성이 떨어지나, 데이터의 안전성이 올라감.\n\n### Durability(지속성)\n\n    - 지속성이란 한번 커밋된 트랜잭션의 결과는 시스템 충돌/전원 장애 후에도 영구 보존됨을 보장하는 특성입니다.\n    - InnoDB는 이를 위해 리두(redo) 로그를 사용:\n    - 트랜잭션이 커밋되면, 변경 내용이 반드시 redo 로그에 디스크로 저장됨을 보장(innodb_flush_log_at_trx_commit 설정).\n    - 버퍼 풀의 변경이 실제 데이터 파일에 늦게 반영되어도, redo 로그만 온전히 남아 있으면 장애 복구가 가능.\n    - Purge/Checkpoint: 일정 시점 체크포인트 후, 기존 redo 로그 공간은 재사용; 언두 로그는 모든 참조가 끝난 후 Purge 스레드가 삭제함.\n    - 실무 팁: 장애 복구를 위해 redo/undo 로그가 저장된 저장소의 안정성과 백업 정책을 강화하세요.\n\n## 결론\n\nMySQL InnoDB는 ACID를 엄격하게 지키기 위해 - 언두/리두 로그, 버퍼 풀, MVCC, 제약조건, 트랜잭션 관리 등 다양한 인프라를 제공합니다. - 성능과 안정성의 균형을 위해 트랜잭션 길이/격리 수준/로그 정책 등 실무 환경에 맞게 튜닝이 필요합니다.\n\n실무 관점 정리:\n• 트랜잭션활용 습관화, 짧고 명확한 구간 사용\n• 제약조건과 트리거, 적절하게 구성\n• 장애 대비를 위한 정기 백업 및 모니터링 설정\n• innodb_flush_log_at_trx_commit 등 지속성 관련 파라미터 주기적 점검\nInnoDB의 ACID는 데이터 신뢰성의 근간입니다. 확고한 원칙 위에서 튜닝과 사용법을 적절히 적용하면, 대규모 서비스에서도 안정적인 데이터 처리가 가능합니다.\n"},{"excerpt":"Trie란? 트라이(Trie)는 문자열을 저장하고 효율적으로 탐색하기 위한 트리 형태의 자료구조이다. 래딕스 트리(radix tree) or 접두사 트리(prefix tree) or 탐색 트리(retrieval tree)라고도 한다. 트라이는 retrieval tree에서 나온 단어이다. 우리가 검색할 때 볼 수 있는 자동완성 기능, 사전 검색 등 문자열…","fields":{"slug":"/Trie/"},"frontmatter":{"date":"April 08, 2025","title":"자료구조 - Trie","tags":["Trie","leetcode"]},"rawMarkdownBody":"\n## Trie란?\n\n- 트라이(Trie)는 문자열을 저장하고 효율적으로 탐색하기 위한 트리 형태의 자료구조이다.\n- 래딕스 트리(radix tree) or 접두사 트리(prefix tree) or 탐색 트리(retrieval tree)라고도 한다. 트라이는 retrieval tree에서 나온 단어이다.\n- 우리가 검색할 때 볼 수 있는 자동완성 기능, 사전 검색 등 문자열을 탐색하는데 특화되어있는 자료구조라고 한다.\n- 예를 들어 'Trie'라는 단어를 검색하기 위해서는 제일 먼저 'T'를 찾고, 다음에 'r', 'i', 'e' 의 순서로 찾으면 된다.\n\n### 특징\n- 트라이(Trie)는 문자열 검색을 빠르게 한다.\n- 트라이는 문자열을 탐색할 때 단순히 비교하는 것에 비해서 효율적으로 찾을 수 있지만, 각 정점이 자식에 대한 링크를 모두 가지고 있기 때문에 저장 공간을 더욱 많이 사용한다는 특징이 있다\n\n## 어떻게 구현하지?\n트라이 자료구조에서 루트는 항상 비어있으며, 각 간선은 추가될 문자를 키로 가지고 있다. 또한, 각 정점은 이전 정점의 값과 간선의 키를 더한 결과를 값으로 가집니다. 트라이를 구현할 때는 이러한 구조를 염두에 두면서 해시 테이블과 연결 리스트를 이용하여 구현할 수 있다.\n\n### 예시\n먼저 Node 를 정의합니다.\n- key에는 해당 노드의 문자가 들어가고, child에는 자식노드가 포함되게 된다.\n- data는 문자열이 끝나는 위치를 알려주는 역할을 한다.\n    - 'car'가 'r'에서 끝날 때, 'r'을 key로 가지는 노드의 data에 'car'를 입력한다.\n- 해당 노드에서 끝나는 문자열이 없을 경우에는 그대로 None으로 내비둔다.\n\n트라이에 \"Trie\" 라는 문자열을 넣는다면 아래와 같이 될 것이다.\n\n![](1.png)\n\n이후 \"Tree\" 라는 문자열을 추가하면 아래와 같이 될 것이다.\n\n![](2.png)\n\n### 탐색 과정\n위의 Trie에 Tre가 있는지 살펴보자.\n1. Head의 children에 T가 존재 --> T노드(key=T)로 이동\n2. T노드의 children에 가 존재 --> r노드(key=r)로 이동\n3. r노드의 children 가 존재 --> e노드(key=e)로 이동\n4. 문자열 탐색이 완료됨 --> 현재 노드(e노드)에 Data값이 없음!\n따라서 'Tre'라는 문자열이 존재하지 않음을 알 수 있다.\n\n### 시간 복잡도\n모든 문자열 개수를 M, 제일 긴 문자열의 길이를 L이라고 하자.\n\n#### 트라이 생성\n모든 문자열 M개를 넣어야하고, M개에 대해서 트라이에 넣는건 가장 긴 문자열 길이인 L만큼 걸리므로 O(M * L)의 시간 복잡도를 가진다. \n\n삽입은 O(L)이다.\n\n#### 트라이 탐색\n트리를 제일 깊게 탐색하는 경우는 가장 긴 문자열 길이인 L개 까지 깊게 들어가는 것이므로 O(L)의 시간 복잡도를 가진다.\n\n\n### 실전\n이 문제를 두 가지 구현으로 풀어보겠다. ([LeetCode 208](https://leetcode.com/problems/implement-trie-prefix-tree/description/))\n\n![](3.png)\n\n#### 해시테이블로 구현\n1. 모든 prefix를 1이라는 값으로 저장한다.\n2. 전체 단어의 경우 2라는 값으로 저장한다.\n\n```python\nclass Trie:\n\n    def __init__(self):\n        self.table = dict()\n\n    // O(n) (n : word length)\n    def insert(self, word: str) -> None:\n        prefix = \"\"\n        for idx in range(1, len(word)):\n            prefix = word[:idx]\n            if prefix not in self.table.keys():\n                self.table[prefix] = 1\n        \n        self.table[word] = 2\n\n    // O(n)\n    def search(self, word: str) -> bool:\n        if word in self.table.keys() and self.table[word] == 2:\n            return True\n        \n        return False\n\n    // O(n)\n    def startsWith(self, prefix: str) -> bool:\n        if prefix in self.table.keys():\n            return True\n        \n        return False\n```\n\n#### 연결 리스트로 구현\n1. Node 클래스를 정의한다.\n2. search 함수를 주어진 형태에 kwargs 를 추가하여 startsWith 함수도 쉽게 처리한다.\n\n```python\nclass Node:\n    def __init__(self, key, data = None):\n        self.key = key\n        self.data = data\n        self.children = dict()\n\n\nclass Trie:\n\n    def __init__(self):\n        self.head = Node(None)\n\n    def insert(self, word: str) -> None:\n        cur = self.head\n        for ch in word:\n            if ch not in cur.children:\n                cur.children[ch] = Node(ch)\n            \n            cur = cur.children[ch]        \n        \n        cur.data = word\n\n    def search(self, word: str, prefix = False) -> bool:\n        cur = self.head\n\n        for ch in word:\n            if ch in cur.children:\n                cur = cur.children[ch]\n            else:\n                return False\n        \n        // startsWith 처리\n        if prefix:\n            return True\n\n        if cur.data is not None:\n            return True\n        \n        return False\n\n    def startsWith(self, prefix: str) -> bool:\n        return self.search(prefix, True)\n\n```\n"},{"excerpt":"아래 과정을 사내 위키에도 작성하였지만 기록으로 남겨두고 싶어 재 작성합니다. \n{: .prompt-info } 개발팀 내부에서 사용하는 mysql계정의 비밀번호를 변경해야 하는 경우가 생겼습니다. 유관 부서에 확인하여 처리해야하는 번거로움은 있지만 작업 자체의 난이도가 높아보이진 않았습니다.  비교적 최근에 Real MySQL 8.0 1권을 읽었던 터라…","fields":{"slug":"/mysql-change-pwd/"},"frontmatter":{"date":"April 02, 2025","title":"MySQL 8.0 계정의 비밀번호 변경하기","tags":["mysql","change password"]},"rawMarkdownBody":"\n> 아래 과정을 사내 위키에도 작성하였지만 기록으로 남겨두고 싶어 재 작성합니다. \n{: .prompt-info }\n\n개발팀 내부에서 사용하는 mysql계정의 비밀번호를 변경해야 하는 경우가 생겼습니다.\n\n유관 부서에 확인하여 처리해야하는 번거로움은 있지만 작업 자체의 난이도가 높아보이진 않았습니다. \n\n비교적 최근에 <u>Real MySQL 8.0 1권</u>[^1]을 읽었던 터라 8.0 부터는 dual password를 지원하고 이를 통해 계정의 비밀번호를 변경할 수 있다는 사실을 알고 있었습니다.\n\n정확한 내용 확인을 위해 홈페이지에서도 내용[^2]을 찾아보았습니다. \n\n이중 비밀번호 기능을 활용하면 긴밀한 협력이나 다운타임 없이 비밀번호를 변경할 수 있다고 합니다. \n \n<blockquote>\nWith dual passwords, credential changes can be made more easily, in phases, without requiring close cooperation, and without downtime:\n<br>이중 비밀번호를 통해 긴밀한 협력이나 다운타임 없이 자격 증명 변경이 쉽게 이루어질 수 있습니다.<br><br>\n\n\n1. For each affected account, establish a new primary password on the servers, retaining the current password as the secondary password. This enables servers to recognize either the primary or secondary password for each account, while applications can continue to connect to the servers using the same password as previously (which is now the secondary password).<br>\n1. 영향을 받는 각 계정에 대해 서버에 새 기본 비밀번호를 설정하고 현재 비밀번호를 보조 비밀번호로 유지합니다. 이를 통해 서버는 각 계정의 기본 또는 보조 비밀번호를 인식할 수 있으며, 어플리케이션은 현재는 보조 비밀번호가 된 이전과 같은 비밀번호를 사용하여 계속해서 서버에 연결할 수 있습니다.<br><br>\n\n2. After the password change has propagated to all servers, modify applications that use any affected account to connect using the account primary password.<br>\n2. 암호 변경 사항이 모든 서버에 전파된 후, 영향을 받는 계정을 사용하는 어플리케이션을 수정하여 계정의 기본 비밀번호를 사용하여 연결합니다.<br><br>\n\n3. After all applications have been migrated from the secondary passwords to the primary passwords, the secondary passwords are no longer needed and can be discarded. After this change has propagated to all servers, only the primary password for each account can be used to connect. The credential change is now complete.<br>\n3. 모든 애플리케이션이 보조 비밀번호에서 기본 비밀번호로 변경된 후에는 보조 비밀번호는 더 이상 필요하지 않으며 삭제할 수 있습니다. 이 변경 사항이 모든 서버에 전파되면, 각 계정의 기본 비밀번호만 사용하여 연결할 수 있습니다.\n</blockquote>\n\n쉽게 생각하면 swap하는 과정과도 비슷한 하다고 느껴집니다. \n\n비밀번호 변경 자체는 매뉴얼에서 제안해준대로 하면 어려움 없이 진행할 수 있습니다.\n\n매뉴얼에는 현재 비밀번호를 보조로 변경하고 새로운 기본 비밀번호를 등록하는 방법, 보조 비밀번호를 삭제하는 방법, 랜덤 비밀번호를 생성하는 방법이 있습니다.\n\n```sql\n-- 이중 비밀번호 설정\nALTER USER 'appuser1'@'host1.example.com'\nIDENTIFIED BY 'password_b'\nRETAIN CURRENT PASSWORD;\n```\n\n```sql\n-- 보조 비밀번호 삭제\nALTER USER 'appuser1'@'host1.example.com'\nDISCARD OLD PASSWORD;\n```\n\n원하던 것은 랜덤한 새로운 비밀번호를 생성하고 이를 기본 비밀번호(현재 비밀번호를 보조 비밀번호로 유지)로 등록하는 것입니다. \n\n이에 대한 내용이 따로 없지만 두 구문을 조합할 수 있을 것 같아 아래와 같은 구문을 개발환경에서 실행해보았습니다.\n\n```sql\nALTER USER\n'username'@'host' IDENTIFIED BY RANDOM PASSWORD\nRETAIN CURRENT PASSWORD;\n```\n\n위 쿼리를 통해 원하는 계정에 랜덤 비밀번호를 추가하고 현재 비밀번호는 보조 비밀번호로 잘 변경되고 연결되는 것도 확인하였습니다.\n\n---\n[^1]: https://product.kyobobook.co.kr/detail/S000001766482\n[^2]: https://dev.mysql.com/doc/refman/8.4/en/password-management.html#dual-passwords"},{"excerpt":"MySQL Connection not available 새로운 프로젝트를 구성하면서 fastapi, SQLModel을 사용하게 되었다. 기존에 SQLAlchemy를 사용하고 있었고 SQLModel이 SQLAlchemy을 랩핑한 패키지 정도로 이해하고 사용하였다. 무난한 코드 작업 이후 코드 단의 오류가 아닌 데이터 베이스와 연관된 오류가 리포트되는 것을 …","fields":{"slug":"/sqlalchemy-connection-pool-not-available/"},"frontmatter":{"date":"April 02, 2025","title":"SQLAlchemy connection pool 설정을 통한 MySQL Connection not available 회피하기","tags":["sqlalchemy","connection","pool_pre_ping","pool_recycle"]},"rawMarkdownBody":"\n## MySQL Connection not available\n새로운 프로젝트를 구성하면서 fastapi, SQLModel을 사용하게 되었다. 기존에 SQLAlchemy를 사용하고 있었고 SQLModel이 SQLAlchemy을 랩핑한 패키지 정도로 이해하고 사용하였다. 무난한 코드 작업 이후 코드 단의 오류가 아닌 데이터 베이스와 연관된 오류가 리포트되는 것을 확인하였다.\n\n![sentry에서 확인되던 오류](1.png)\n\n해당 오류를 읽어보면 **mysql.connector.errors.OperationalError: MySQL Connection not available.** 가 키 포인트 인 것을 알 수 있다. 왜 멀쩡한(?) 커넥션을 사용할 수 없다고 하는 것일까? ~~내 세션 왜 아파...~~\n\n\n## 원인 추측\n그 이유는 sqlalchemy 의 세션 풀에 있다. 세션 풀이란 세션을 생성할 때 발생하는 비용을 줄이고 보다 효율적으로 세션을 사용하기 위해 사용하는 방식으로 sqlalchemy에서도 지원하고 있다. \n\n**'세션 풀에서 유효하지 않은 세션을 받았고 이를 가지고 요청하려던 것은 아닐까'** 하는 생각이 들었다. 실제로 RDS 콘솔에서 아래 쿼리로 사용했던 세션이 wait_timeout을 넘어간 뒤, 리포트 되던 api 를 요청해본 결과 같은 오류가 재현해볼 수 있었다.\n\n사실 wait_timeout을 더 길게 늘리면 보편적으로 해당 연결이 만료되기 전에 다시 사용될 여지가 있긴 하지만 결국 임시 방편이다.\n\n근본적인 원인을 해결하고 싶었다. sqlalchemy에서 커넥션은 쿼리가 실행되거나 트랜잭션이 시작할 때 생성되기 때문에 그 전에 해당 세션이 유효한지 확인하고 사용할 수 있다면 해당 오류를 해결할 수 있지 않을까 생각했다.\n\n## 해결\n### pool_pre_ping과 pool_recycle\n그래서 연결에 관해 이에 도움이 될 수 있는 옵션들을 찾다보니 pool\\_pre\\_ping[^1] 과 pool_recycle[^2]을 찾았다. \n\n> pool_pre_ping: 데이터베이스 연결이 사용되기 전에 'select 1' 을 통해 해당 연결의 유효성을 확인하고 유효하지 않을 경우 연결을 재생성한다.\n\n> pool_recycle: wait timeout 이전에 설정한 값을 넘긴 세션은 애플리케이션의 커넥션 풀에 유지되다가, 해당 세션을 사용하려고 하면 무조건 폐기되고 새로운 연결로 재생성된다.\n\n두 옵션에 미묘한 차이가 있다면 이런 것이다. pool_pre_ping은 연결이 유효하지 않은 경우 새 연결을 생성하는 반면, pool_recycle은 유효하지 않을 가능성이 있는 연결을 미리 재생성한다.\n\n**여기서 유의해야 할 점은 pool_recycle을 설정할 때는 wait_timeout보다 짧게 설정해야 의미가 있다.** 이미 연결이 끊어진 뒤에야 재 설정하려고 한다면 무슨 의미인가.\n\n조금 걱정되었던 부분은 pool_pre_ping의 경우 select 1 을 통해 모든 쿼리 전에 연결 상태를 확인하는 추가 작업이 들어가기 때문에, 성능에 약간의 오버헤드가 발생할 수 있지만 일반적으로 매우 작기도 하고 사내 백오피스 기능 중 일부분이라 걱정없이 적용하기로 하였다.\n\n위에서 찾은 내용들을 바탕으로 config에 두 값을 추가해보았다.\n![](2.png)\n\n테스트 환경에서 확인해본 뒤에 상용 환경에 배포하였다. \n![](3.png)\n\n더 이상 오류가 올라오지 않는다. 만세. \n\n이 외에도 DB관련해서 오류가 종종 보이는데 시간 내서 확인해보고 수정해봐야겠다.\n\n> 1. The client was disconnected by the server because of inactivity. See wait_timeout and interactive_timeout for configuring this behavior.\n>\n> 2. MySQLInterfaceError - Unknown MySQL server host 'host name'\n\n---\n[^1]: https://docs.sqlalchemy.org/en/14/core/pooling.html#dealing-with-disconnects\n[^2]: https://docs.sqlalchemy.org/en/14/core/pooling.html#setting-pool-recycle"},{"excerpt":"REST api 를 개발할 때 테스트를 위해 postman 을 자주 사용합니다. 로컬환경에서 테스트하거나, QA나 운영 이슈로 인해 개발 환경 혹은 상용 환경의 api 를 테스트해볼 일이 생깁니다. 그때마다 사용하는 url을 매번 다시 입력해주었는데 사실 번거롭지 그지 없습니다. 누군가 저에게 이런 말씀을 해주신 적이 있습니다.  손이 느리고 게으른 개발…","fields":{"slug":"/postman-config/"},"frontmatter":{"date":"April 02, 2025","title":"postman 환경 변수 사용하기","tags":["postman"]},"rawMarkdownBody":"\nREST api 를 개발할 때 테스트를 위해 postman 을 자주 사용합니다. 로컬환경에서 테스트하거나, QA나 운영 이슈로 인해 개발 환경 혹은 상용 환경의 api 를 테스트해볼 일이 생깁니다. 그때마다 사용하는 url을 매번 다시 입력해주었는데 사실 번거롭지 그지 없습니다. 누군가 저에게 이런 말씀을 해주신 적이 있습니다. \n\n> 손이 느리고 게으른 개발자가 성공한다.\n\n손이 빠르고 게으르지 않은 사람은 그냥 해버리는 경우가 있다며... 아마 귀찮은 반복을 줄여나가고 불편함을 해소해 나가는 것에서 성장이 시작된다는 의미가 아니었을까 합니다. 그래서 겸사겸사 귀찮은 반복을 없애기 위해 postman에서 제공하는 환경 변수를 사용해보았습니다.\n\n## 환경 변수 설정하기\n테스트할 api 는 자주 사용하는 것은 있어도 같다고 보장할 수 없으니 host 나 port 번호에 대해 환경 변수를 적용하였습니다.\n\n![변수 추가하기](1.png)\n\n![add를 눌러보자](2.png)\n\nadd 를 누르면 환경과 해당 환경에서 사용할 변수를 추가할 수 있습니다.\n\n![local 환경 추가](3.png)\n\n위와 같이 환경이름과 환경 변수를 추가하였습니다. 저장하면 다음과 같이 환경이 생성된 것을 볼 수 있습니다.\n\n![설정 후 사용해보기](4.png)\n\n저장 후 local이라는 환경이 생김과 동시에 설정했던 변수들을 사용할 수 있는 것을 확인할 수 있습니다.\n\n환경변수를 추가하는 방법은 또 있습니다.\n\n![환경 변수 설정하는 다른 방법](5.png)\n\n환경 변수로 설정하고 싶은 값을 더블 클릭 하면 위와 같이 **set as variable** 이 나타납니다. 이 버튼을 클릭하면 마찬가지로 환경 변수에 추가할 수 있습니다.\n\n![](6.png)\n\n![](7.png)\nlocal 이라는 환경에서 새로 추가한 환경 변수를 확인할 수 있습니다.\n"},{"excerpt":"기존에 사용한 블로그에서 글을 옮겼습니다. 비슷한 내용을 발견하실 수도 있습니다. 현상 서비스에서 배치를 aws의 code deploy를 이용하여 배포와 관리하고 있습니다. 아쉽게도 code deploy에서의 이벤트 로그에 대한 모니터링은 없어 지난주부터 발생한 아래 에러를 늦게 발견한 상황이었고 배포가 제대로 이루어지지 않은 것을 알게 되었습니다.  해…","fields":{"slug":"/code-deploy-failure/"},"frontmatter":{"date":"March 22, 2025","title":"Code deploy 는 왜 배포에 실패했을까?","tags":["AWS","Code deploy"]},"rawMarkdownBody":"> 기존에 사용한 블로그에서 글을 옮겼습니다. 비슷한 내용을 발견하실 수도 있습니다.\n\n## 현상\n서비스에서 배치를 aws의 code deploy를 이용하여 배포와 관리하고 있습니다. 아쉽게도 code deploy에서의 이벤트 로그에 대한 모니터링은 없어 지난주부터 발생한 아래 에러를 늦게 발견한 상황이었고 배포가 제대로 이루어지지 않은 것을 알게 되었습니다.\n\n![](1.png)\n\n## 해결\n메세지를 보아 agent 에 문제가 있을 수 있다는 생각을 하게 되었고 인스턴스에 ssh 접속을 통해 확인하고자 했습니다. 그 결과 아래 처럼 codedeploy agent의 상태가 비활성상태인 것을 알게 되었고 재시작시켜주었습니다. 이후 code deploy를 통해 인스턴스에 원활히 배포가 된 것을 확인할 수 있었습니다.\n\n![](2.png)\n\n실제 서비스에서 사용중인 인프라가 아니라 서비스에 영향은 없었지만 배포가 안되었을 때 바로 알아차리지 못했다는 것은 아쉬운 부분이었습니다. 이에 대한 모니터링 방법과 agent 의 상태를 추적할 수 있는지도 확인이 필요하겠습니다.\n\n## 참고\nhttps://docs.aws.amazon.com/ko_kr/codedeploy/latest/userguide/codedeploy-agent-operations-verify.html"},{"excerpt":"기존에 사용한 블로그에서 글을 옮겼습니다. 비슷한 내용을 발견하실 수도 있습니다. 지난번에 CodeDeploy에 배포가 제대로 되지 않으면서 배치가 제대로 돌지 못한 일이 있었습니다.  이에 어플리케이션의 배포 결과를 슬랙으로 알림을 받아 볼 수 있도록 설정해보았습니다.  전체 흐름은 다음과 같습니다. CodeDeploy 배포 성공/실패 -> SNS ->…","fields":{"slug":"/code-deploy-alert/"},"frontmatter":{"date":"March 22, 2025","title":"Code deploy에 알림을 추가하자","tags":["AWS","Code deploy"]},"rawMarkdownBody":"\n> 기존에 사용한 블로그에서 글을 옮겼습니다. 비슷한 내용을 발견하실 수도 있습니다.\n\n지난번에 CodeDeploy에 배포가 제대로 되지 않으면서 배치가 제대로 돌지 못한 일이 있었습니다. \n\n이에 어플리케이션의 배포 결과를 슬랙으로 알림을 받아 볼 수 있도록 설정해보았습니다. \n\n전체 흐름은 다음과 같습니다.\n\nCodeDeploy 배포 성공/실패 -> SNS -> Lambda -> Slack\n\n## Lambda 생성\n먼저 AWS Lambda 로 가서 새로운 함수를 생성해 줍니다. 함수의 역할은 이벤트 발생시 해당 이벤트의 메세지에서 필요한 내용을 가공하여 슬랙 채널로 발송하는 것입니다.\n\n```python\nimport boto3\nimport json\nimport logging\nimport os\n\nfrom base64 import b64decode\nfrom urllib.request import Request, urlopen\nfrom urllib.error import URLError, HTTPError\n\nfrom datetime import datetime, timedelta\n\nHOOK_URL = os.environ['HOOK_URL']\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n\ndef lambda_handler(event, context):\n    def utc_to_kst(d):\n        d = datetime.strptime(d, \"%a %b %d %H:%M:%S %Z %Y\")\n        return (d + timedelta(hours=9)).strftime(\"%Y-%m-%d %H:%M:%S\")\n        \n        \n    logger.info(\"Event: \" + str(event))\n    message = json.loads(event['Records'][0]['Sns']['Message'])\n    subject = event['Records'][0]['Sns']['Subject']\n    logger.info(\"Message: \" + str(message))\n\n    event_trigger_name = message['eventTriggerName']\n    status = message['status']\n    app_name = message['applicationName']\n    deploy_group_name = message['deploymentGroupName']\n    deploy_id = message['deploymentId']\n    create_time = message['createTime']\n    complete_time = message['completeTime']\n    \n    logger.info(utc_to_kst(create_time))\n    \n    color = 'good'\n    if status.lower() == 'failed':\n        color = 'danger'\n    \n    fields = [\n        {\n            \"title\" : \"Task\",\n            \"value\" : event_trigger_name,\n            \"short\" : True\n        },\n        {\n            \"title\" : \"Status\",\n            \"value\" : status,\n            \"short\" : True\n        },\n        {\n            \"title\" : \"Application\",\n            \"value\" : app_name,\n            \"short\" : True\n        },\n        {\n            \"title\" : \"Deployment Group\",\n            \"value\" : deploy_group_name,\n            \"short\" : True\n        },\n        {\n            \"title\" : \"Region\",\n            \"value\" : message['region'],\n            \"short\" : True\n        },\n        {\n            \"title\" : \"Deployment Link\",\n            \"value\" : 'https://'+message.get('region')+'.console.aws.amazon.com/codedeploy/home?region='+message.get('region')+'#/deployments/'+deploy_id,\n            \"short\" : True\n        },\n        {\n            \"title\" : \"Create Time\",\n            \"value\" : utc_to_kst(create_time),\n            \"short\" : True\n        },\n        {\n            \"title\" : \"Complete Time\",\n            \"value\" : utc_to_kst(complete_time),\n            \"short\" : True\n        },\n        {\n            \"title\" : \"Error Code\",\n            \"value\" : message.get('errorInformation', {}).get('ErrorCode'),\n            \"short\" : True\n        },\n        {\n            \"title\" : \"Error Message\",\n            \"value\" : message.get('errorInformation', {}).get('ErrorMessage'),\n            \"short\" : True\n        }\n    ]\n    \n    slack_message = {\n        'text': subject,\n        'username': 'CodeDeploy',\n        'icon_emoji': ':codedeploy:',\n        'channel': os.environ['slackChannel'],\n        'attachments': [\n            {\n                'fields': fields,        \n                'color': color,\n            }\n        ]\n    }\n\n    req = Request(HOOK_URL, json.dumps(slack_message).encode('utf-8'))\n    try:\n        response = urlopen(req)\n        response.read()\n        logger.info(\"Message posted\")\n    except HTTPError as e:\n        logger.error(\"Request failed: %d %s\", e.code, e.reason)\n    except URLError as e:\n        logger.error(\"Server connection failed: %s\", e.reason)\n```\n\n해당 코드는 [이동욱님의 블로그](https://jojoldu.tistory.com/298)를 참고하였습니다. 코드 작성 이외에 환경 변수에 슬랙 채널과 webhook 주소를 등록해주었습니다.\n\n## AWS SNS 주제 생성\n위에서 람다를 새로 생성하였지만 이를 트리거 시킬 것이 없는 상태입니다. 따라서 작성한 람다가 잘 동작할 수 있게 SNS를 추가하려고 합니다. 생성 이후 작성한 람다에 트리거로 추가해주면 됩니다. ~~이름은 무시해주세요.~~\n\n![](1.png)\n\n## 어플리케이션에 트리거 추가\n\n이제 마지막으로 해주어야 할 것은 앞서 SNS에 생성한 주제를 CodeDeploy의 이벤트가 발생했을 시 SNS로 전송하도록 하는 것입니다.\n\n원하는 어플리케이션 선택 -> 편집 -> 고급 에 아래와 같이 트리거를 생성하였습니다. 트리거 생성시 미리 생성해둔 SNS를 선택하면 됩니다.\n\n![](2.png)\n\n## 결과\n\n배포 성공 시 아래와 같은 결과를 슬랙에서 받아볼 수 있습니다.\n\n![](3.png)\n"},{"excerpt":"기존에 사용한 블로그에서 글을 옮겼습니다. 비슷한 내용을 발견하실 수도 있습니다. 에러 확인 며칠 전 새로운 프로젝트 세팅을 하던 도중 프로젝트 폴더가 깜박이듯 한 현상을 발견했다. 코드를 작성하려고 하면 루트 폴더가 사라져 아무 것도 할 수가 없었다. 별다른 에러 메세지나 팝업이 없었기에 당황스러웠다.  비슷한 현상이 있었을 것이라 생각하고 구글에서 찾…","fields":{"slug":"/pycharm-operation-not-permitted/"},"frontmatter":{"date":"March 20, 2025","title":"PyCharm - Operation not permitted","tags":["Error"]},"rawMarkdownBody":"> 기존에 사용한 블로그에서 글을 옮겼습니다. 비슷한 내용을 발견하실 수도 있습니다.\n\n## 에러 확인\n며칠 전 새로운 프로젝트 세팅을 하던 도중 프로젝트 폴더가 깜박이듯 한 현상을 발견했다.\n\n코드를 작성하려고 하면 루트 폴더가 사라져 아무 것도 할 수가 없었다. 별다른 에러 메세지나 팝업이 없었기에 당황스러웠다.\n\n![](1.gif)\n\n비슷한 현상이 있었을 것이라 생각하고 구글에서 찾아보려고 했으나 6-7년 전의 글들만 나오고 그마저도 제시된 해결책들은 나에게는 해당사항이 없었다. \n\n그런던 중에 PyCharm에도 에러 로그가 있다는 사실을 알았다. ~~있을 것이라고 생각도 못했다.~~\n\n에러 로그를 보니 해당 현상이 나타날 때 반복적으로 보이는 에러가 있었다.\n![로그는 여기에서 확인 가능하다.](2.png)\n\n![](3.png)\n\n저런 에러들로 찾아도 별다른 방법은 없었\n\n## 갑자기 해결\n갑자기 든 생각은 PyCharm이 해당 디렉토리로의 접근 자체를 못하고 있는 것은 아닐까 하는 생각이 들었다. 보통 앱을 설치할 때 팝업을 통해 설정해 주는 그 영역이 문제가 아닐까 싶었다. 기존에 사용하던 중 intel chip에서 apple silicon으로 기기를 변경하면서 새롭게 앱을 설치했는데 해당 설정을 하지 않았던 기억도 났다.\n\n`system settings > privacy & security > files and folders` 에서 PyCharm에게 접근 권한을 주었다.\n\n그랬더니 귀신같이 해당 현상이 사라지더라... 근 1주일을 고통 받았는데 한순간에 사라지니 속시원했다. 앱과 프로젝트를 몇 번이나 재설정하고 mac os도 업데이트 했는데 해결안되서 우울증 걸릴 지경이었다.\n\n마지막으로 나와 비슷한 고민을 한 사람이 있는 것 같아 stack overflow에 답글도 달아주었다. 저 사람은 해결했을까?\n\n> [비슷한 문제를 겪은 것으로 보이는 stackoverflow 글](https://stackoverflow.com/questions/77699707/intellij-crashing-in-mac-apple-chip-with-operation-not-permitted/78098412#78098412)\n"},{"excerpt":"기존에 작성했던 포스트의 내용을 정리하고 추가하였습니다. 개요 서비스를 운영하다보니 사용자의 요청이 몰리는 시간대에 DB의 cpu 사용률이 90% 이상을 도달하며 간당간당한 상황이 이어지고 있었다. 부하를 줄이기 위해 읽기 복제본도 두고 있었지만 문제를 해결하기에는 역부족이었다. 정석적으로는 슬로우 쿼리를 찾아 쿼리 튜닝을 하고 필요 시 어플리케이션 로직…","fields":{"slug":"/rds-scale-up/"},"frontmatter":{"date":"November 28, 2022","title":"AWS RDS 스케일 업","tags":["rds","scale-up"]},"rawMarkdownBody":"\n> 기존에 작성했던 포스트의 내용을 정리하고 추가하였습니다.\n\n## 개요\n\n서비스를 운영하다보니 사용자의 요청이 몰리는 시간대에 DB의 cpu 사용률이 90% 이상을 도달하며 간당간당한 상황이 이어지고 있었다. 부하를 줄이기 위해 읽기 복제본도 두고 있었지만 문제를 해결하기에는 역부족이었다. 정석적으로는 슬로우 쿼리를 찾아 쿼리 튜닝을 하고 필요 시 어플리케이션 로직에서 처리하도록 변경하거나 경우에 따라서는 스케일업이나 스케일 아웃도 고려해야 한다고 생각했다. 당시 가까운 미래에 큰 이벤트를 앞두고 있어 시간이 많지 않았고 적용 후 곧장 효과를 볼 것으로 기대되는 스케일업을 선택하게 되었다.\n\n## 그래서 어떻게 하지?\n\n유료 고객으로부터 돈을 받아서 서비스를 하는 입장에서 필수불가결한 상황이 아니면 중단은 피하고자 했기 때문에 최소한의 중단 시간을 가능케 하는 방법들을 살펴보았다. 공식문서와 실제 적용 사례들을 찾아보고, 외부 DBA 에게 자문하여 나름의 PoC를 진행하였다.\n\n### PoC\n\n- Multi AZ Cluster - 서울지역 미지원\n  - [2025.09.09 추가] [공식문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.Limitations.html)에 리전 제한에 대한 내용이 없는 것으로 보아 현재는 지원하는 것으로 보인다.\n- Multi AZ Instance + 서비스 점검 시간\n  - 점검 시간을 두어 트랜잭션이 0인 상태에서 장애조치를 통한 스케일업\n- RDS proxy\n  - 추가 인프라를 구성해야 함\n- Aurora DB로의 마이그레이션\n  - 읽기 복제본이 장애조치에 활용되어 금액적인 이득과 HA 구성이 가능\n  - RI(예약 인스턴스)와의 호환도 고려가 필요\n- DMS를 이용한 마이그레이션\n- 읽기복제본의 승격\n  - endpoint를 직접 수정해야 함\n\n각각의 방법에 대한 자세한 내용은 따로 생략한다.\n\nMulti AZ Instance에 대한 내용을 간단하게 정리하면 아래와 같다.\n\n- 다른 AZ에 대기 인스턴스를 두어 장애조치를 자동으로 진행할 수 있어 고가용성 구성을 도모할 수 있다.\n- 읽기 복제본을 두는 것과는 무관하다.\n- 하지만 대기 인스턴스는 서비스에 직접 사용할 수는 없고 어디까지나 문제가 있는 경우 장애 조치용으로 존재하기에 사용하게 되는 비용이 다소 증가할 수 있다.\n\n### 테스트와 실제 반영\n\n실제 live 환경에 적용하기에 앞서 실제와 비슷한 환경에서의 테스트를 진행하려 했다. live DB의 스냅샷을 다른 지역에 전송하여 이를 바탕으로 인스턴스를 생성하고, 실제와 같이 Multi AZ 설정과 장애조치로 걸리는 시간을 대략적으로 측정함과 운영 반영 시나리오를 작성 및 테스트하기 위함이었다. 테스트에서 아쉬웠던 점은 실제로는 서비스 점검 시간 없이 진행할 것이라 locust로 요청을 만들면서 그 사이에 진행하였는데 RPS(초당 요청 수)가 충분하지 못해 테스트에서 소요된 시간보다 실제에서 더 걸릴 것으로 예상했다.\n\n실제 운영 반영은 테스트 이후 새벽 시간에 요청이 적은 시간을 골라 진행되었다. 예상대로 테스트보다 시간이 더 걸리기는 하였으나 multi az 설정과 원하던 크기의 인스턴스로 변경하여 큰 문제없이 스케일 업을 마무리할 수 있었다.\n\n## 결과\n\n피크 시간마다 문제가 되었던 RDS의 CPU 사용률은 크게 줄어들어 안정적인 모습을 보여주었다.\n\n하지만 live DB의 읽기 지연시간이 크게 증가하였고 이에 대한 여러 추측을 해보았지만 명확한 이유는 알 수 없었다.\n일주일 정도가 지난 후에는 기존과 비슷한 수준의 지연시간을 보여 일시적인 현상으로 보이기도 한다.\n\n## 보완할 점\n\n### 실제와 같은 테스트\n\n실제 운영 트래픽을 테스트 DB에도 반영할 수 있었으면 어떘을까 싶다. 실제 트래픽 재현을 위해 운영 요청 로그를 통해 트래픽을 재현해보는 방법도 있겠고, 실제 운영 트래픽을 테스트 DB 로도 전달하는 것도 방법이 될 수 있겠다.\n\n물론 DB와 서버 인스턴스가 필요하니 비용이 더 들겠지만 실제 운영 환경에서의 스케일업과 영향도를 파악하는데는 보다 정확한 판단이 가능하지 않을까 싶다.\n\n### read latency의 증가\n\n실제로 스케일 업을 진행한 후 약 1주일 간 기존과 다르게 눈의 띄게 높은 읽기 지연 시간이 있었다.\n\n![ReadLatency가 요동쳤다.](latency1.png)\n\n확실히 기존과는 다른 패턴인 것을 알 수 있다. 수치가 크지는 않지만 기존과 차이가 크다는 점에 주목했다. 결과적으로 일주일 정도가 지난 시점에는 기존과 비슷한 모양을 보이기 시작했다.\n\n![다시 돌아오기는 했다.](latency2.png)\n\n당시에 [aws 블로그](https://repost.aws/ko/knowledge-center/rds-write-latency-spikes)에서 찾아보았던 내용은 아래와 같다.\n\n> 지연 로딩은 특정 시점으로 복원, 단일 AZ 인스턴스를 다중 AZ 인스턴스로 변환, 새 읽기 전용 복제본 생성 등 스냅샷에서 복원해야 하는 모든 시나리오에서 발생할 수 있습니다. 아직 로드되지 않은 데이터에 액세스하려고 하면 DB 인스턴스는 Amazon Simple Storage Service(S3)에서 요청된 데이터를 즉시 다운로드합니다. 그런 다음 인스턴스는 백그라운드에서 나머지 데이터를 계속 로드합니다. 자세한 내용은 Amazon EBS 스냅샷 생성을 참조하십시오. 빠른 액세스가 필요한 테이블에 대한 지연 로딩의 영향을 완화하기 위해 SELECT\\*와 같이 전체 테이블 스캔을 포함하는 작업을 수행할 수 있습니다. 이렇게 하면 RDS가 Amazon S3에서 백업된 모든 테이블 데이터를 다운로드할 수 있습니다.\n\n전에 비해 아직 로드되지 않은 데이터가 존재하여 기존과 같이 읽기 동작에서 지연이 있구나 정도로 이해했다.\n\n지금에서야 드는 생각은 비슷한 맥락으로 innodb의 버퍼 풀에 적재된 데이터가 없기 때문에 이를 채우는 시간이 필요하지 않았을까 싶다. 버퍼풀과 관련된 설정을 통해 빠르게 버퍼풀을 채울 수 있었다면 읽기 지연이 정상화 되는데 걸리는 시간이 줄어들지 않았을까 하는 생각도 든다.\n\n이 부분도 실제 트래픽을 통해 스케일 업을 미리 시해행하였다면 확인해 볼 수 있는 수치가 아니었을까 싶다.\n"}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}